# MscIDS_Computational_Language_Technologies

These three notebooks were created during the module "Computational Language Technologies" during the 4. Semester of the Msc Applied Information and Data Science on the Lucerne University of Applied Science.

Each notebook has predefined goals and contains different NLP-Tasks.

## Notebooks

[Exercise 1](https://github.com/SandroSuter92/MscIDS_Computational_Language_Technologies/blob/main/Ex01_Sandro_Suter.ipynb)

Pick a topic that you are interested in and exists as a Wikipedia category or subcategory and extract the title, summary (and anything else you like, e.g., German equivalents).

Organize (and clean) the data into a dataframe. Add text features (length of title/description, TTR, POSs), and conduct an exploratory data & text analysis, e.g., missing data points, length of lead section, inspect content of text.

Summarize your learnings including shortcomings of the used NLP tools and text.

[Exercise 2](https://github.com/SandroSuter92/MscIDS_Computational_Language_Technologies/blob/main/Ex02_Sandro_Suter.ipynb)

Find Dataset - The goal is to find and define a Dataset on wich I can train my own word embedding. Concerning the source of the data, there are no restrictions

Train word2vec or GloVe embeddings and visualize the semantic space - The goal is to compare the self trained embeddings to a pretrained space.

Summarize - Draw conclusions about learnings, pro- and contra regarding pretrained embeddings

[Exercise 3](https://github.com/SandroSuter92/MscIDS_Computational_Language_Technologies/blob/main/Ex03_Sandro_Suter.ipynb)

Do end-to-end 'Named Entity Recognition (NER)' or 'Neural Machine Translation(NMT)' using a Deep Learning and a Transfer Learning model of your choosing. This contains the follwoing subtasks:

- Choose dataset

- Data preparation

- Data analysis

- Data preprocessing

- Embedding

- Training

- Evaluation

As a dataset you can use Huggingface as a source. The only restriction regarding the data is, that it has to contain at least 15'000 samples.

